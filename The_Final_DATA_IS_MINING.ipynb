{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGyFlpt23cVw"
      },
      "source": [
        "https://www.youtube.com/watch?v=p-3e0EkvIEM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emfSds2L9gRD"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start_time = time.time()  #start time elapsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1cdGXmYrnGk",
        "outputId": "0c4de6a6-7198-4cf9-f098-758eecbb7522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyGithub in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: pynacl>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (1.5.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from PyGithub) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (2.31.0)\n",
            "Requirement already satisfied: pyjwt[crypto]>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (4.5.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (2.0.7)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from PyGithub) (1.2.14)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (41.0.7)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl>=1.4.0->PyGithub) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (2023.11.17)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->PyGithub) (1.14.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->PyGithub) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.21)\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.2)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (2.13.3)\n",
            "Collecting visualkeras\n",
            "  Downloading visualkeras-0.0.2-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (9.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (1.23.5)\n",
            "Collecting aggdraw>=1.3.11 (from visualkeras)\n",
            "  Downloading aggdraw-1.3.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.7/993.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aggdraw, visualkeras\n",
            "Successfully installed aggdraw-1.3.18 visualkeras-0.0.2\n"
          ]
        }
      ],
      "source": [
        "%pip install PyGithub\n",
        "%pip install --quiet vit-keras\n",
        "%pip install tensorflow_addons\n",
        "%pip install visualkeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U-P9ZuzrtUw"
      },
      "outputs": [],
      "source": [
        "from github import Github\n",
        "\n",
        "# Access the repository with your token\n",
        "g = Github(\"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\")\n",
        "repo = g.get_repo(\"olivesmoo/ai-art-detector\")\n",
        "\n",
        "# Get a file by its path\n",
        "midjourney = repo.get_contents(\"datasets/parsed_midjourney_images\")\n",
        "wikiart = repo.get_contents(\"datasets/wikiart_samples\")\n",
        "artstation = repo.get_contents(\"datasets/artstation_sample\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S27XyeFZkNiB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import visualkeras\n",
        "\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
        "from tensorflow.keras.applications import MobileNet, ResNet50\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import losses, models, layers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet101\n",
        "from tensorflow.keras.applications import VGG19\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc, confusion_matrix, precision_recall_curve\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "#for parsing im\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import base64\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from vit_keras import vit\n",
        "from vit_keras import visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP48hEoF8ZYZ"
      },
      "source": [
        "# Image Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFnZ5qn48bsC",
        "outputId": "91313f37-ba7f-4767-ac93-883826e8fd84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/0465b5565f5bd7a5529c3e776f371c94c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd0e5e7fb0>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/0ca10b49a2543c273df13abcde4671a3c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd0e663dd0>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/0ec0e2fc4eec5dab19ebe44d3a523b00c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd0e663dd0>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/0fd7778a0ea8ac27efbaa7ad12fa4bc0c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd0e5b3600>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/1536960428a75673810b99245c540526c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd3afdf970>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/1a2afe4b0ebdc8a0cfb8cf259e2c5bb0c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd12688130>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/1f76a3dcf6dea45ea5e2c1f772fb18afc.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd3afebe70>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/242ed0ad8258e0252a36dede8968b871c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd3afebe70>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/2e5ecb28b345fc3b013b6c833175050fc.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd0e59b970>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/3ed31c530bef99733786d51cc442bfd4c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd3b03fc40>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/425f9cfd25cfd7a82278ededebd7a9aac.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd0e787740>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/4d8835897110f4c241f7e18651d9cc60c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd3a49b650>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/4dcb96a0b47a575c03fcd4da1fe3b458c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd3b047c90>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/5df8eb07598cb41a288c3a7f0b697f45c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd3b09bd80>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/6b1192ce6f61a46f3053852e045e8db3c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd3b0c31f0>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/6f1692d01d427ceb4235afe9bf60a8cdc.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd3aecfb00>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/741b23bca618db3eee29b1511ee8d227c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd3b024bd0>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/74f20f87704fa4cef7c6c3ccf6f5d816c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd3b082e80>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/76d19376679f3a5e90197fdfb9eb924ec.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd3aed7740>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/7931d81d431877b5b58fdc30e4e0c35cc.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd3b082e80>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/7ea8b59929be2c7b21abaf2715b27f37c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd3aef7f10>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/8360c6146f755c44a1f242f70eb9de5dc.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd3af0f3d0>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/8400390e8343a866d15fcfcdc657b393c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd0f31c860>\n",
            "Error processing wikiart image ContentFile(path=\"datasets/wikiart_samples/856c7f3b4a2bafb2a7ba55d783c08535c.jpg\"): cannot identify image file <_io.BytesIO object at 0x7edd3b098ea0>\n"
          ]
        }
      ],
      "source": [
        "# Human-created art labels\n",
        "labels_real = []\n",
        "imgs_real = []\n",
        "filenames_real = [] # just for bookkeeping purposes\n",
        "\n",
        "for filename in artstation:\n",
        "  try:\n",
        "    image_data = BytesIO(base64.b64decode(filename.content))\n",
        "    img = Image.open(image_data).convert('RGB')\n",
        "    img = img.resize((224, 224))\n",
        "    img_array = np.array(img) / 255.0\n",
        "\n",
        "    imgs_real.append(img_array)\n",
        "    labels_real.append(0)\n",
        "    filenames_real.append(filename.name)\n",
        "\n",
        "    if len(imgs_real) == 250:\n",
        "      break\n",
        "\n",
        "  except Exception as e:\n",
        "        print(f\"Error processing artstation image {filename}: {str(e)}\")\n",
        "\n",
        "for filename in wikiart:\n",
        "  try:\n",
        "    image_data = BytesIO(base64.b64decode(filename.content))\n",
        "    img = Image.open(image_data).convert('RGB')\n",
        "    img = img.resize((224, 224))\n",
        "    img_array = np.array(img) / 255.0\n",
        "\n",
        "    imgs_real.append(img_array)\n",
        "    labels_real.append(0)\n",
        "    filenames_real.append(filename.name)\n",
        "\n",
        "    if len(imgs_real) == 500:\n",
        "      break\n",
        "\n",
        "  except Exception as e:\n",
        "        print(f\"Error processing wikiart image {filename}: {str(e)}\")\n",
        "\n",
        "# AI-generated art\n",
        "labels_ai = []\n",
        "imgs_ai = []\n",
        "filenames_ai = [] # just for bookkeeping purposes\n",
        "\n",
        "for filename in midjourney:\n",
        "  try:\n",
        "    image_data = BytesIO(base64.b64decode(filename.content))\n",
        "    img = Image.open(image_data).convert('RGB')\n",
        "    img = img.resize((224, 224))\n",
        "    img_array = np.array(img) / 255.0\n",
        "\n",
        "    imgs_ai.append(img_array)\n",
        "    labels_ai.append(1)\n",
        "    filenames_ai.append(filename.name)\n",
        "\n",
        "    if len(imgs_ai) == 500:\n",
        "      break\n",
        "\n",
        "  except Exception as e:\n",
        "        print(f\"Error processing midjourney image {filename}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qeGDthkK7Fk",
        "outputId": "7a14cf63-a600-490a-ba19-3aafc7e16ed8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of AI art:  500\n",
            "Number of Human art:  500\n"
          ]
        }
      ],
      "source": [
        "print('Number of AI art: ',len(imgs_ai))\n",
        "print('Number of Human art: ',len(imgs_real))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EApW0sdLTBC"
      },
      "outputs": [],
      "source": [
        "imgs_real = np.asarray(imgs_real)\n",
        "imgs_ai = np.asarray(imgs_ai)\n",
        "labels_real = np.asarray(labels_real)\n",
        "labels_ai = np.asarray(labels_ai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtNEe6A9LsvF"
      },
      "outputs": [],
      "source": [
        "features = np.concatenate((imgs_real, imgs_ai), axis=0)\n",
        "labels = np.concatenate((labels_real, labels_ai), axis=0)\n",
        "features = features.astype('float32')\n",
        "labels = labels.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs9sTeOxL-ZU"
      },
      "outputs": [],
      "source": [
        "# Split the combined data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting sets\n",
        "# print(\"Training set - Features:\", X_train.shape, \" Labels:\", y_train.shape)\n",
        "# print(\"Testing set - Features:\", X_test.shape, \" Labels:\", y_test.shape)\n",
        "\n",
        "# Reshape the labels to a 2D array (required by OneHotEncoder)\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "y_test = y_test.reshape(-1, 1)\n",
        "\n",
        "# Create a OneHotEncoder instance\n",
        "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
        "\n",
        "# Fit the encoder on training labels and transform both training and testing labels\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.transform(y_test)  # Use transform() for testing labels\n",
        "\n",
        "# Print the shapes of the transformed sets\n",
        "# print(\"Training set - Features:\", X_train, \" Labels:\", y_train)\n",
        "# print(\"Testing set - Features:\", X_test, \" Labels:\", y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdpLpwaG3E5H"
      },
      "source": [
        "# Functions for Metrics and Visuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SS2LJBsg3RmZ"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(history):\n",
        "    # Extracting training and validation accuracy and loss from the history\n",
        "    accuracy = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    # Plotting accuracy\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(accuracy, label='Training Accuracy')\n",
        "    plt.plot(val_accuracy, label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plotting loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(loss, label='Training Loss')\n",
        "    plt.plot(val_loss, label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i552X-oF3pRf"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_classified, y_true):\n",
        "  # Compute confusion matrix\n",
        "  c_mat = np.zeros((2,2))\n",
        "  for i in range(len(y_true)):\n",
        "    c_mat[y_classified[i], y_true[i]] += 1\n",
        "  group_counts = [\"{0:0.0f}\".format(value) for value in c_mat.flatten()]\n",
        "  group_percentages = [\"{0:.2%}\".format(value) for value in c_mat.flatten()/np.sum(c_mat)]\n",
        "  labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts, group_percentages)]\n",
        "  labels = np.asarray(labels).reshape(c_mat.shape[0], c_mat.shape[1])\n",
        "\n",
        "  accuracy = np.sum(y_classified == y_true) / len(y_true)*100\n",
        "\n",
        "\n",
        "  plt.figure(figsize=(12,10))\n",
        "  sn.heatmap(c_mat, annot=labels, fmt='', cmap='rocket_r')\n",
        "  plt.title(\"Confusion Matrix\")\n",
        "  plt.ylabel('Output Class')\n",
        "  plt.xlabel('Target Class \\n Accuracy: ' + '%.2f'%accuracy + \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9CVjOyS7OOa"
      },
      "source": [
        "# RESNET-50 Base Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5gq-ILR7OOo",
        "outputId": "1e5c58ed-ae7b-4fd9-acea-f638700b1ee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 100353    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23688065 (90.36 MB)\n",
            "Trainable params: 100353 (392.00 KB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# ResNet50\n",
        "# Assume your input image shape is (224, 224, 3)\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 2\n",
        "\n",
        "# Load the pre-trained ResNet50 model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Freeze the weights of the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create your custom model on top of the ResNet base\n",
        "resnet_model = models.Sequential()\n",
        "resnet_model.add(base_model)\n",
        "resnet_model.add(layers.Flatten())\n",
        "resnet_model.add(layers.Dense(1, activation='sigmoid'))  # Binary classification uses 'sigmoid'\n",
        "\n",
        "# Compile the model\n",
        "resnet_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "resnet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "cs4NhSHJ7OOo",
        "outputId": "39c1494e-a9e8-4da1-87a5-6a5c0133f106"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#plotting resnet50 model\n",
        "plot_model(resnet_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3sEzDGw7OOp"
      },
      "outputs": [],
      "source": [
        "visualkeras.layered_view(resnet_model, legend=True, to_file='model_plot.png').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjVFsr497OOp",
        "outputId": "356439d5-e779-4b35-c994-a90d83392459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 199s 8s/step - loss: 1.3131 - accuracy: 0.5200 - val_loss: 0.8022 - val_accuracy: 0.5750\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 193s 8s/step - loss: 0.7216 - accuracy: 0.6125 - val_loss: 0.5200 - val_accuracy: 0.7250\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 192s 8s/step - loss: 0.5801 - accuracy: 0.7150 - val_loss: 0.5257 - val_accuracy: 0.6700\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 193s 8s/step - loss: 0.4940 - accuracy: 0.7387 - val_loss: 0.4617 - val_accuracy: 0.7950\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 201s 8s/step - loss: 0.4622 - accuracy: 0.7750 - val_loss: 0.5177 - val_accuracy: 0.7050\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 195s 8s/step - loss: 0.4527 - accuracy: 0.7763 - val_loss: 0.5084 - val_accuracy: 0.7100\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 194s 8s/step - loss: 0.4485 - accuracy: 0.7688 - val_loss: 0.4446 - val_accuracy: 0.7900\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 187s 8s/step - loss: 0.4141 - accuracy: 0.8100 - val_loss: 0.7207 - val_accuracy: 0.6300\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 181s 7s/step - loss: 0.4215 - accuracy: 0.7950 - val_loss: 0.5972 - val_accuracy: 0.6250\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 187s 8s/step - loss: 0.3873 - accuracy: 0.8225 - val_loss: 0.3803 - val_accuracy: 0.8550\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 181s 7s/step - loss: 0.3945 - accuracy: 0.8163 - val_loss: 0.4884 - val_accuracy: 0.7550\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 185s 8s/step - loss: 0.3430 - accuracy: 0.8575 - val_loss: 0.3623 - val_accuracy: 0.8600\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 184s 7s/step - loss: 0.3800 - accuracy: 0.8250 - val_loss: 0.4493 - val_accuracy: 0.7650\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 187s 8s/step - loss: 0.3973 - accuracy: 0.8050 - val_loss: 0.4282 - val_accuracy: 0.7750\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 187s 8s/step - loss: 0.3803 - accuracy: 0.8200 - val_loss: 0.4053 - val_accuracy: 0.8150\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 187s 8s/step - loss: 0.2930 - accuracy: 0.8950 - val_loss: 0.4740 - val_accuracy: 0.7550\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 187s 8s/step - loss: 0.2889 - accuracy: 0.8838 - val_loss: 0.3502 - val_accuracy: 0.8600\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 187s 8s/step - loss: 0.2887 - accuracy: 0.9050 - val_loss: 0.5238 - val_accuracy: 0.7050\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 188s 8s/step - loss: 0.3123 - accuracy: 0.8550 - val_loss: 0.3977 - val_accuracy: 0.8300\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 194s 8s/step - loss: 0.2771 - accuracy: 0.9025 - val_loss: 0.4249 - val_accuracy: 0.7900\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 185s 7s/step - loss: 0.3060 - accuracy: 0.8637 - val_loss: 0.3330 - val_accuracy: 0.8800\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 184s 7s/step - loss: 0.2530 - accuracy: 0.9025 - val_loss: 0.3925 - val_accuracy: 0.8000\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 188s 8s/step - loss: 0.2522 - accuracy: 0.8950 - val_loss: 0.3356 - val_accuracy: 0.8650\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 188s 8s/step - loss: 0.2795 - accuracy: 0.8863 - val_loss: 0.4257 - val_accuracy: 0.7850\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 187s 8s/step - loss: 0.2586 - accuracy: 0.8963 - val_loss: 0.3255 - val_accuracy: 0.8800\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 188s 8s/step - loss: 0.2790 - accuracy: 0.8838 - val_loss: 0.3495 - val_accuracy: 0.8400\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 189s 8s/step - loss: 0.3036 - accuracy: 0.8537 - val_loss: 0.5047 - val_accuracy: 0.7350\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 185s 7s/step - loss: 0.3713 - accuracy: 0.8375 - val_loss: 0.3916 - val_accuracy: 0.7950\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 187s 8s/step - loss: 0.3131 - accuracy: 0.8462 - val_loss: 0.3733 - val_accuracy: 0.8450\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 186s 7s/step - loss: 0.2843 - accuracy: 0.8725 - val_loss: 0.3277 - val_accuracy: 0.8700\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 184s 7s/step - loss: 0.2109 - accuracy: 0.9312 - val_loss: 0.3305 - val_accuracy: 0.8600\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 188s 8s/step - loss: 0.2631 - accuracy: 0.9025 - val_loss: 0.3280 - val_accuracy: 0.8750\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 188s 8s/step - loss: 0.2264 - accuracy: 0.9137 - val_loss: 0.5280 - val_accuracy: 0.7400\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 187s 8s/step - loss: 0.2447 - accuracy: 0.8950 - val_loss: 0.3227 - val_accuracy: 0.8800\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 187s 8s/step - loss: 0.2104 - accuracy: 0.9225 - val_loss: 0.3312 - val_accuracy: 0.8650\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 188s 8s/step - loss: 0.2122 - accuracy: 0.9175 - val_loss: 0.3304 - val_accuracy: 0.8700\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 184s 7s/step - loss: 0.2322 - accuracy: 0.8925 - val_loss: 0.4084 - val_accuracy: 0.8050\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 186s 8s/step - loss: 0.2026 - accuracy: 0.9262 - val_loss: 0.3376 - val_accuracy: 0.8500\n",
            "Epoch 39/50\n",
            " 8/25 [========>.....................] - ETA: 1:39 - loss: 0.1766 - accuracy: 0.9297"
          ]
        }
      ],
      "source": [
        "epochs = 50  # Adjust as needed\n",
        "\n",
        "#train the model, after this cell is finished running the training for the model is complete\n",
        "history = resnet_model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_nNVsRvm7OOp"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = resnet_model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "threshold = 0.5\n",
        "y_pred_binary = (y_pred > threshold).astype(int)\n",
        "\n",
        "# convert one-hot encoded y_test to binary\n",
        "y_test_binary = y_test.astype(int)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Classification Report\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test_binary, y_pred_binary))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n",
        "\n",
        "# ROC Curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test_binary, y_pred_binary)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test_binary, y_pred_binary)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(recall, precision, color='blue', lw=2)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n",
        "\n",
        "# F1 Score\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "max_f1_index = np.argmax(f1)\n",
        "best_threshold = thresholds[max_f1_index]\n",
        "best_f1 = f1[max_f1_index]\n",
        "\n",
        "print(f'Best F1 Score: {best_f1:.4f} at threshold {best_threshold:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CpBvUOoB7OOp"
      },
      "outputs": [],
      "source": [
        "precision, recall, fscore, _ = precision_recall_fscore_support(y_test_binary, y_pred_binary, zero_division=1)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F-score:\", fscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tdveX3iq7OOp"
      },
      "outputs": [],
      "source": [
        "#plotting training and validation accuracy/loss by epochs\n",
        "plot_training_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qHud1q3M7OOp"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_pred_binary, y_test_binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylkVSbVS074t"
      },
      "source": [
        "# RESNET-50 Augmented Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C27m4D6ToxD-"
      },
      "outputs": [],
      "source": [
        "# ResNet50\n",
        "# Assume your input image shape is (224, 224, 3)\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 2\n",
        "\n",
        "# Load the pre-trained ResNet50 model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Freeze the weights of the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create custom model on top of the ResNet base\n",
        "resnet_model = models.Sequential()\n",
        "resnet_model.add(base_model)\n",
        "resnet_model.add(layers.Flatten())\n",
        "resnet_model.add(layers.Dense(256, activation='relu'))\n",
        "resnet_model.add(layers.Dropout(0.5))\n",
        "resnet_model.add(layers.Dense(1, activation='sigmoid'))  # Binary classification uses 'sigmoid'\n",
        "\n",
        "# Compile the model\n",
        "resnet_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "resnet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lhhWyueE6Su-"
      },
      "outputs": [],
      "source": [
        "#diagram for resnet50 augmented\n",
        "plot_model(resnet_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IF4wfHiP6zfH"
      },
      "outputs": [],
      "source": [
        "!pip install visualkeras\n",
        "import visualkeras\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "visualkeras.layered_view(resnet_model, legend=True, to_file='model_plot.png').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yMBrVhD6m5l"
      },
      "outputs": [],
      "source": [
        "epochs = 50  # Adjust as needed\n",
        "\n",
        "#train the model, after this cell is finished running the training for the model is complete\n",
        "history = resnet_model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kdxY-dQ6d13"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = resnet_model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "threshold = 0.5\n",
        "y_pred_binary = (y_pred > threshold).astype(int)\n",
        "\n",
        "# convert one-hot encoded y_test to binary\n",
        "y_test_binary = y_test.astype(int)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Classification Report\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test_binary, y_pred_binary))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n",
        "\n",
        "# ROC Curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test_binary, y_pred_binary)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test_binary, y_pred_binary)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(recall, precision, color='blue', lw=2)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n",
        "\n",
        "# F1 Score\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "max_f1_index = np.argmax(f1)\n",
        "best_threshold = thresholds[max_f1_index]\n",
        "best_f1 = f1[max_f1_index]\n",
        "\n",
        "print(f'Best F1 Score: {best_f1:.4f} at threshold {best_threshold:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Jgc2Q5npRPa"
      },
      "outputs": [],
      "source": [
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F-score:\", fscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmIXRyZrl1ba"
      },
      "outputs": [],
      "source": [
        "#plot training/validation accuracy and loss for resnet50 augmented\n",
        "plot_training_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZG9Mdo2oDwB"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_pred_binary, y_test_binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1ofD7Xn7kQW"
      },
      "source": [
        "# RESNET-101 Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7MZIQCi7kQh"
      },
      "outputs": [],
      "source": [
        "model_fun = ResNet101(weights='imagenet', input_shape=(224, 224, 3), include_top=False, classes=2)\n",
        "\n",
        "# Freeze the weights of the pre-trained layers\n",
        "for layer in model_fun.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create custom model on top of the ResNet base\n",
        "resnet_model = models.Sequential()\n",
        "resnet_model.add(model_fun)\n",
        "resnet_model.add(layers.Flatten())\n",
        "resnet_model.add(layers.Dense(1, activation='sigmoid'))  # Binary classification uses 'sigmoid'\n",
        "\n",
        "# Compile the model\n",
        "resnet_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "resnet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YF2xecpm7kQh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "#displaying resnet101 base model\n",
        "plot_model(resnet_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mN8LgMgI7kQh"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "\n",
        "history1 = resnet_model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrBuf89G7kQi"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = resnet_model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "threshold = 0.5\n",
        "y_pred_binary = (y_pred > threshold).astype(int)\n",
        "\n",
        "# convert y_test to binary\n",
        "y_test_binary = y_test.astype(int)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Classification Report\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test_binary, y_pred_binary))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n",
        "\n",
        "# ROC Curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test_binary, y_pred_binary)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test_binary, y_pred_binary)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(recall, precision, color='blue', lw=2)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n",
        "\n",
        "# F1 Score\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "max_f1_index = np.argmax(f1)\n",
        "best_threshold = thresholds[max_f1_index]\n",
        "best_f1 = f1[max_f1_index]\n",
        "\n",
        "print(f'Best F1 Score: {best_f1:.4f} at threshold {best_threshold:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtxEXyg-7kQi"
      },
      "outputs": [],
      "source": [
        "precision, recall, fscore, _ = precision_recall_fscore_support(y_test_binary, y_pred_binary, zero_division=1)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F-score:\", fscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ0PaoFn7kQi"
      },
      "outputs": [],
      "source": [
        "plot_training_history(history1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AX5qWzAv7kQi"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_pred_binary, y_test_binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AiiphnulmUl"
      },
      "source": [
        "# RESNET-101 Augmented Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-Htl75UsHf1"
      },
      "outputs": [],
      "source": [
        "model_fun = ResNet101(weights='imagenet', input_shape=(224, 224, 3), include_top=False, classes=2)\n",
        "\n",
        "# Freeze the weights of the pre-trained layers\n",
        "for layer in model_fun.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create custom model on top of the ResNet base\n",
        "resnet_model = models.Sequential()\n",
        "resnet_model.add(model_fun)\n",
        "resnet_model.add(layers.Flatten())\n",
        "resnet_model.add(layers.Dense(256, activation='relu'))\n",
        "resnet_model.add(layers.Dropout(0.5))\n",
        "resnet_model.add(layers.Dense(1, activation='sigmoid'))  # Binary classification uses 'sigmoid'\n",
        "\n",
        "# Compile the model\n",
        "resnet_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "resnet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFLOXXuSjFpH"
      },
      "outputs": [],
      "source": [
        "plot_model(resnet_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcWwNVpRs7rY"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "\n",
        "#train the model, after this cell is finished running the training for the model is complete\n",
        "history1 = resnet_model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbP8Z4ohxEo7"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = resnet_model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "threshold = 0.5\n",
        "y_pred_binary = (y_pred > threshold).astype(int)\n",
        "\n",
        "# convert y_test to binary\n",
        "y_test_binary = y_test.astype(int)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Classification Report\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test_binary, y_pred_binary))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n",
        "\n",
        "# ROC Curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test_binary, y_pred_binary)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test_binary, y_pred_binary)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(recall, precision, color='blue', lw=2)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n",
        "\n",
        "# F1 Score\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "max_f1_index = np.argmax(f1)\n",
        "best_threshold = thresholds[max_f1_index]\n",
        "best_f1 = f1[max_f1_index]\n",
        "\n",
        "print(f'Best F1 Score: {best_f1:.4f} at threshold {best_threshold:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gv_i6LW9xX95"
      },
      "outputs": [],
      "source": [
        "precision, recall, fscore, _ = precision_recall_fscore_support(y_test_binary, y_pred_binary, zero_division=1)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F-score:\", fscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98P6Z1qexkSL"
      },
      "outputs": [],
      "source": [
        "plot_training_history(history1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YJvv4D_xy9R"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_pred_binary, y_test_binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfOJfwBkjTj-"
      },
      "source": [
        "# VGG19 Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkvklj-tjajb"
      },
      "outputs": [],
      "source": [
        "input_shape = (224, 224, 3)\n",
        "num_classes = 2\n",
        "\n",
        "# Load the pre-trained VGG19 model\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Freeze the weights of the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create custom model on top of the VGG19 base\n",
        "vgg_model = models.Sequential()\n",
        "vgg_model.add(base_model)\n",
        "vgg_model.add(layers.Flatten())\n",
        "vgg_model.add(layers.Dense(1, activation='sigmoid'))  # Binary classification uses 'sigmoid'\n",
        "\n",
        "# Compile the model\n",
        "vgg_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "vgg_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EIPPp3Rj7Ky"
      },
      "outputs": [],
      "source": [
        "epochs = 50  # Adjust as needed\n",
        "\n",
        "#train the model, after this cell is finished running the training for the model is complete\n",
        "history2 = vgg_model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4fNVBm6kByD"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = vgg_model.predict(X_test)\n",
        "print('before pred '+str(y_pred))\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "threshold = 0.5\n",
        "y_pred_binary = (y_pred > threshold).astype(int)\n",
        "print('after pred '+str(y_pred))\n",
        "\n",
        "# convert y_test to binary\n",
        "y_test_binary = y_test.astype(int)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Classification Report\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test_binary, y_pred_binary))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n",
        "\n",
        "# ROC Curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test_binary, y_pred_binary)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(recall, precision, color='blue', lw=2)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n",
        "\n",
        "# F1 Score\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "max_f1_index = np.argmax(f1)\n",
        "best_threshold = thresholds[max_f1_index]\n",
        "best_f1 = f1[max_f1_index]\n",
        "\n",
        "print(f'Best F1 Score: {best_f1:.4f} at threshold {best_threshold:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEu2j6cmkTls"
      },
      "outputs": [],
      "source": [
        "precision, recall, fscore, _ = precision_recall_fscore_support(y_test_binary, y_pred_binary, zero_division=1)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F-score:\", fscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sR2saXjPkWZp"
      },
      "outputs": [],
      "source": [
        "plot_training_history(history2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXsxS3Tyk3pL"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_pred_binary, y_test_binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQiPwk6A4M0K"
      },
      "source": [
        "# ViTL32 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiwWfxvM4Xqt"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 2\n",
        "INPUT_SHAPE = (224, 224, 3)\n",
        "\n",
        "# DATA\n",
        "BUFFER_SIZE = 16\n",
        "\n",
        "# AUGMENTATION\n",
        "IMAGE_SIZE = 224\n",
        "PATCH_SIZE = 6\n",
        "NUM_PATCHES = (IMAGE_SIZE // PATCH_SIZE) ** 2\n",
        "\n",
        "# OPTIMIZER\n",
        "LEARNING_RATE = 0.001 #change to 0.0001 in next run through\n",
        "WEIGHT_DECAY = 0.0001\n",
        "\n",
        "# TRAINING\n",
        "EPOCHS = 50\n",
        "\n",
        "# ARCHITECTURE\n",
        "LAYER_NORM_EPS = 1e-6\n",
        "TRANSFORMER_LAYERS = 8\n",
        "PROJECTION_DIM = 64\n",
        "NUM_HEADS = 4\n",
        "TRANSFORMER_UNITS = [\n",
        "    PROJECTION_DIM * 2,\n",
        "    PROJECTION_DIM,\n",
        "]\n",
        "MLP_HEAD_UNITS = [2048, 1024]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqoYGDJZ4_Uq"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 224\n",
        "vit_model = vit.vit_l32(\n",
        "        image_size = IMAGE_SIZE,\n",
        "        activation = 'sigmoid',\n",
        "        weights = \"imagenet21k\",\n",
        "        include_top=True,\n",
        "        classes = 2)\n",
        "\n",
        "# Add custom head for binary classification\n",
        "custom_head = layers.Dense(1, activation='sigmoid')(vit_model.output)\n",
        "\n",
        "# Create the final model with the custom head\n",
        "vit_model = tf.keras.Model(inputs=vit_model.input, outputs=custom_head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH7xiYhm5CtH"
      },
      "outputs": [],
      "source": [
        "# creates graph executation error\n",
        "optimizer = tfa.optimizers.AdamW(\n",
        "    learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "vit_model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "vit_model.summary()\n",
        "#train the model, after this cell is finished running the training for the model is complete\n",
        "history = vit_model.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=EPOCHS,\n",
        ")\n",
        "# _, accuracy = vit_model.evaluate(X_test, y_test)\n",
        "# print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ5jVomD5Ke5"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = vit_model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "threshold = 0.5\n",
        "y_pred_binary = (y_pred > threshold).astype(int)\n",
        "\n",
        "# convert y_test to binary\n",
        "y_test_binary = y_test.astype(int)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Classification Report\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test_binary, y_pred_binary))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n",
        "\n",
        "# ROC Curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test_binary, y_pred_binary)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test_binary, y_pred_binary)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(recall, precision, color='blue', lw=2)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n",
        "\n",
        "# F1 Score\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "max_f1_index = np.argmax(f1)\n",
        "best_threshold = thresholds[max_f1_index]\n",
        "best_f1 = f1[max_f1_index]\n",
        "\n",
        "print(f'Best F1 Score: {best_f1:.4f} at threshold {best_threshold:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7Jh_Ylf5Ne7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision, recall, fscore, _ = precision_recall_fscore_support(y_test_binary, y_pred_binary, zero_division=1)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F-score:\", fscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgw6RKJa5QF9"
      },
      "outputs": [],
      "source": [
        "plot_training_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a596EwXw5Tf9"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_pred_binary, y_test_binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwJNU8Lx-Qmi"
      },
      "outputs": [],
      "source": [
        "end_time = time.time()\n",
        "print('elapsed time in seconds:')\n",
        "print(end_time-start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61YxETaoCp5D"
      },
      "source": [
        "# ViTB32 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRhhTcBrCp5S"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 2\n",
        "INPUT_SHAPE = (224, 224, 3)\n",
        "\n",
        "# DATA\n",
        "BUFFER_SIZE = 16\n",
        "\n",
        "# AUGMENTATION\n",
        "IMAGE_SIZE = 224\n",
        "PATCH_SIZE = 6\n",
        "NUM_PATCHES = (IMAGE_SIZE // PATCH_SIZE) ** 2\n",
        "\n",
        "# OPTIMIZER\n",
        "LEARNING_RATE = 0.001 #change to 0.0001 in next run through\n",
        "WEIGHT_DECAY = 0.0001\n",
        "\n",
        "# TRAINING\n",
        "EPOCHS = 50\n",
        "\n",
        "# ARCHITECTURE\n",
        "LAYER_NORM_EPS = 1e-6\n",
        "TRANSFORMER_LAYERS = 8\n",
        "PROJECTION_DIM = 64\n",
        "NUM_HEADS = 4\n",
        "TRANSFORMER_UNITS = [\n",
        "    PROJECTION_DIM * 2,\n",
        "    PROJECTION_DIM,\n",
        "]\n",
        "MLP_HEAD_UNITS = [2048, 1024]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtHytf7zCp5S"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 224\n",
        "vit_model = vit.vit_b32(\n",
        "        image_size = IMAGE_SIZE,\n",
        "        activation = 'sigmoid',\n",
        "        weights = \"imagenet21k\",\n",
        "        include_top=True,\n",
        "        classes = 2)\n",
        "\n",
        "# Add your custom head for binary classification\n",
        "custom_head = layers.Dense(1, activation='sigmoid')(vit_model.output)\n",
        "\n",
        "# Create the final model with the custom head\n",
        "vit_model = tf.keras.Model(inputs=vit_model.input, outputs=custom_head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOMP92MeCp5S"
      },
      "outputs": [],
      "source": [
        "# creates graph executation error\n",
        "optimizer = tfa.optimizers.AdamW(\n",
        "    learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "vit_model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "vit_model.summary()\n",
        "\n",
        "#train the model, after this cell is finished running the training for the model is complete\n",
        "history = vit_model.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=EPOCHS,\n",
        ")\n",
        "# _, accuracy = vit_model.evaluate(X_test, y_test)\n",
        "# print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKamIzY2Cp5S"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Make predictions\n",
        "y_pred = vit_model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "threshold = 0.5\n",
        "y_pred_binary = (y_pred > threshold).astype(int)\n",
        "\n",
        "# convert y_test to binary\n",
        "y_test_binary = y_test.astype(int)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Classification Report\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test_binary, y_pred_binary))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n",
        "\n",
        "# ROC Curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test_binary, y_pred_binary)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test_binary, y_pred_binary)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(recall, precision, color='blue', lw=2)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n",
        "\n",
        "# F1 Score\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "max_f1_index = np.argmax(f1)\n",
        "best_threshold = thresholds[max_f1_index]\n",
        "best_f1 = f1[max_f1_index]\n",
        "\n",
        "print(f'Best F1 Score: {best_f1:.4f} at threshold {best_threshold:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcQFRbq_Cp5T"
      },
      "outputs": [],
      "source": [
        "precision, recall, fscore, _ = precision_recall_fscore_support(y_test_binary, y_pred_binary, zero_division=1)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F-score:\", fscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leoostfuCp5T"
      },
      "outputs": [],
      "source": [
        "plot_training_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJP4QeezCp5T"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_pred_binary, y_test_binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp-pIulTCp5T"
      },
      "outputs": [],
      "source": [
        "end_time = time.time()\n",
        "print('elapsed time in seconds:')\n",
        "print(end_time-start_time)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}